{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import copy\n",
    "import re\n",
    "import argparse, sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Layer, Dense, Input, Dropout, Conv2D, BatchNormalization, Activation, Flatten, Concatenate, MaxPooling2D\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "import keras.backend as K\n",
    "from keras.layers import Lambda\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "\n",
    "from scipy import stats\n",
    "import scipy\n",
    "\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value= 12345\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(\"Keras version: \", keras.__version__)\n",
    "\n",
    "#Define hyperparameters\n",
    "seq_length = 60\n",
    "n_filters = 10\n",
    "filter_size = 3\n",
    "n_layers = 4\n",
    "n_nodes = 40\n",
    "dropout_rate = 0.25 \n",
    "\n",
    "#Define Pepper model\n",
    "class CustomLossLayer(layers.Layer):\n",
    "    def __init__(self, n_proteins_layer, n_runs_layer, **kwargs):\n",
    "\n",
    "        super(CustomLossLayer, self).__init__()\n",
    "        self.n_proteins_layer = n_proteins_layer\n",
    "        self.n_runs_layer = n_runs_layer\n",
    "\n",
    "        #Define alpha variables that are trainable\n",
    "        if n_proteins_layer == 1584 and n_runs_layer == 1:\n",
    "            self.alphas = tf.Variable(alpha_initial_train, \n",
    "                                  trainable = True, \n",
    "                                  dtype = 'float32')\n",
    "        else:\n",
    "\n",
    "            init_values = np.random.rand(1527, \n",
    "                                         96) \n",
    "            self.alphas = tf.Variable(init_values, \n",
    "                                      trainable = True, \n",
    "                                      dtype = 'float32')\n",
    "\n",
    "    def get_vars(self):\n",
    "        return self.alphas\n",
    "\n",
    "    def peptide_loss(self, y_true, y_pred):\n",
    "\n",
    "        #Define all inputs\n",
    "        c_pred = K.abs(y_pred)\n",
    "        c_pred = tf.reshape(c_pred,[-1]) #this is very important for correctness of calculation\n",
    "        q_input = y_true[:, :-1] #dimension (batch_size, K)\n",
    "        label_input = y_true[:, -1] #dimension (batch_size, 1)\n",
    "        label_input = tf.cast(label_input, tf.int32)\n",
    "\n",
    "        #Exclude missing intensities in pairwise distance calculation\n",
    "        zero_peptides = K.not_equal(q_input, K.constant(0))\n",
    "        zero_peptides = K.cast(zero_peptides, K.floatx())\n",
    "\n",
    "        #Exclude peptides with 0 coefficients in pairwise distance calculation\n",
    "        zero_coeffs = K.not_equal(c_pred, K.constant(0))\n",
    "        zero_coeffs = K.cast(zero_coeffs, K.floatx())\n",
    "        zero_coeffs = tf.expand_dims(zero_coeffs, 1)\n",
    "\n",
    "        #Find the corresponding alpha value for each peptide\n",
    "        corresponding_protein_abundances = tf.gather(K.abs(self.alphas), label_input, axis = 0)\n",
    "\n",
    "        #Calculate adjusted abundances\n",
    "        c_pred = tf.expand_dims(c_pred, 1)\n",
    "        adjusted_abundances = c_pred * corresponding_protein_abundances\n",
    "\n",
    "        #Calculate the difference values\n",
    "        differences = q_input - adjusted_abundances\n",
    "        differences = differences * zero_peptides * zero_coeffs\n",
    "        differences = K.square(differences)\n",
    "\n",
    "        #Return the mean loss\n",
    "        total_loss = K.sum(differences)\n",
    "        all_runs = K.sum(zero_peptides * zero_coeffs)\n",
    "        return total_loss / all_runs\n",
    "\n",
    "    #We add the loss to the final model loss\n",
    "    def call(self, y_true, y_pred):\n",
    "        self.add_loss(self.peptide_loss(y_true, y_pred))\n",
    "        return y_pred\n",
    "\n",
    "#Define alpha-based peptide loss function\n",
    "def peptide_loss(x, c_pred, alphas):\n",
    "\n",
    "    c_pred = K.abs(c_pred)\n",
    "\n",
    "    #q_input is the intensity values from the experiment\n",
    "    q_input = x[:, :-1] #dimension (batch_size, K)\n",
    "    #label_input is the protein labels for each peptide\n",
    "    label_input = x[:, -1] #dimension (batch_size, 1)\n",
    "    label_input = tf.cast(label_input, tf.int32)\n",
    "\n",
    "    c_pred = tf.reshape(c_pred,[-1]) #this is very important for correctness of calculation\n",
    "\n",
    "    #Exclude missing intensities in pairwise distance calculation\n",
    "    zero_peptides = K.not_equal(q_input, K.constant(0))\n",
    "    zero_peptides = K.cast(zero_peptides, K.floatx())\n",
    "\n",
    "    #Exclude peptides with 0 coefficients in pairwise distance calculation\n",
    "    zero_coeffs = K.not_equal(c_pred, K.constant(0))\n",
    "    zero_coeffs = K.cast(zero_coeffs, K.floatx())\n",
    "    zero_coeffs = tf.expand_dims(zero_coeffs, 1)\n",
    "\n",
    "    #Find the corresponding alpha value for each peptide\n",
    "    corresponding_protein_abundances = tf.gather(K.abs(alphas), label_input, axis = 0)\n",
    "\n",
    "    #Calculate the differences\n",
    "    c_pred = tf.expand_dims(c_pred, 1)\n",
    "    adjusted_abundances = c_pred * corresponding_protein_abundances\n",
    "    differences = q_input - adjusted_abundances\n",
    "    differences = differences * zero_peptides * zero_coeffs\n",
    "    differences = K.square(differences)\n",
    "\n",
    "    #Record final average loss\n",
    "    total_loss = K.sum(differences)\n",
    "    all_runs = K.sum(zero_peptides * zero_coeffs)\n",
    "    return total_loss / all_runs\n",
    "\n",
    "#Define model\n",
    "def define_model(n_proteins_layer, n_runs_layer):\n",
    "\n",
    "    #Define custom absolute valued activation function\n",
    "    def absActivation(x) :\n",
    "        activated_x = K.abs(x)\n",
    "        return activated_x\n",
    "\n",
    "    #Define network\n",
    "    inputs =  Input(shape=(seq_length, 20, 1), name = 'sequence')\n",
    "    inputs_charge = Input(shape=(6,), name = 'charge')\n",
    "    inputs_label = Input(shape=(n_runs_layer + 1,), name = 'y_true')\n",
    "\n",
    "    #Define convolutional layers\n",
    "    x = Conv2D(n_filters, kernel_size=(filter_size, 20), activation=\"relu\", input_shape=(seq_length, 20, 1))(inputs)\n",
    "    x = MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    sequence_representation = Flatten()(x)\n",
    "    sequence_representation = Dropout(dropout_rate)(sequence_representation)\n",
    "\n",
    "    #Second input is the one-hot encoded charge states\n",
    "    concatenated_representation = Concatenate()([sequence_representation, inputs_charge])\n",
    "    x = concatenated_representation\n",
    "\n",
    "    #Define dense layers\n",
    "    for n in range(n_layers):\n",
    "        x = Dense(n_nodes, activation=\"relu\")(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "    output = Dense(1, activation=absActivation)(x) #predict peptide coefficients\n",
    "\n",
    "    #Define model with custom layer\n",
    "    my_custom_layer = CustomLossLayer(n_proteins_layer, n_runs_layer)(inputs_label, output) # here can also initialize those var1, var2\n",
    "    model = Model(inputs = [inputs, inputs_charge, inputs_label], outputs = my_custom_layer)\n",
    "    model.summary()\n",
    "\n",
    "    #Compile the model\n",
    "    opt = tf.optimizers.Adam(learning_rate = 1e-3, clipnorm = 1)\n",
    "    model.compile(optimizer=opt)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "#Load pretrained model\n",
    "pretrained_model = define_model(1527, 96)   \n",
    "pretrained_model.load_weights('../trained_models/2019_guo_nci60/2019_guo_nci60_Coefficient_Predictor_Model.h5')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Generate sequences with substitutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the peptide sequences from dataset 1\n",
    "sequence_df = pd.read_csv('../preprocess_datasets/preprocessed_datasets/2019_guo_nci60_formatted_peptide_quants.tsv',\n",
    "                          sep = '\\t', index_col = 0)\n",
    "\n",
    "#Modify the sequences to exclude modifications\n",
    "peptide_sequences = sequence_df['Peptide'].values\n",
    "peptide_sequences = [s.replace('(UniMod:4)', '') for s in peptide_sequences]\n",
    "peptide_sequences = [s.replace('(UniMod:35)', '') for s in peptide_sequences]\n",
    "\n",
    "charges = sequence_df[['Charge 1', 'Charge 2', 'Charge 3', 'Charge 4', 'Charge 5', 'Charge 6']].values\n",
    "print(\"Number of sequences \", len(peptide_sequences))\n",
    "\n",
    "peptide_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = generateSequences(peptide_sequences, charges, sample_size = 5000)\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode simulated sequences\n",
    "all_sequence_pairs = results[0] \n",
    "all_sequence_pairs_onehot_encoded = results[1] \n",
    "all_sequence_pairs_charges = np.array(results[2])\n",
    "\n",
    "pair1_sequences = np.array(all_sequence_pairs_onehot_encoded)[:,:60 * 20]\n",
    "pair1_sequences = np.array(pair1_sequences).reshape((pair1_sequences.shape[0], 60, 20))\n",
    "pair1_sequences = np.expand_dims(pair1_sequences, axis=3)\n",
    "\n",
    "pair1_charges = all_sequence_pairs_charges[:, 0]\n",
    "\n",
    "pair1_coefficients = pretrained_model.predict([pair1_sequences, pair1_charges,\n",
    "                                               np.ones((pair1_sequences.shape[0],97))]).ravel()\n",
    "pair1_coefficients = np.abs(pair1_coefficients)\n",
    "pair1_coefficients = pd.DataFrame(pair1_coefficients)\n",
    "print(\"Pair 1 coefficients \", pair1_coefficients)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Encode simulated sequences\n",
    "pair2_sequences =  np.array(all_sequence_pairs_onehot_encoded)[:, -1 * 60 * 20:]\n",
    "pair2_sequences = np.array(pair2_sequences).reshape((pair2_sequences.shape[0], 60, 20))\n",
    "pair2_sequences = np.expand_dims(pair2_sequences, axis=3)\n",
    "\n",
    "\n",
    "pair2_charges = all_sequence_pairs_charges[:, 1]\n",
    "\n",
    "pair2_coefficients = pretrained_model.predict([pair2_sequences, pair2_charges,\n",
    "                                               np.ones((pair2_sequences.shape[0],97))]).ravel()\n",
    "pair2_coefficients = np.abs(pair2_coefficients)\n",
    "pair2_coefficients = pd.DataFrame(pair2_coefficients)\n",
    "print(\"Pair 2 coefficients \", pair2_coefficients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate coefficient differences\n",
    "coeff_differences = pair1_coefficients.values.ravel() - pair2_coefficients.values.ravel() \n",
    "coeff_differences = pd.DataFrame(coeff_differences, index = all_sequence_pairs.index, columns = ['Coefficient Difference'])\n",
    "coeff_differences = coeff_differences.abs()\n",
    "\n",
    "coeff_differences['Start Position'] = results[0]['Start Position'].values\n",
    "coeff_differences['End Position'] = results[0]['End Position'].values\n",
    "\n",
    "coeff_differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Create substitution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plot with std error\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(35, 20)\n",
    "\n",
    "SMALL_SIZE = 60\n",
    "MEDIUM_SIZE = 80\n",
    "BIGGER_SIZE = 90\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    " \n",
    "all_scores = coeff_differences.groupby('Start Position')['Coefficient Difference'].apply(lambda x:np.mean(x.abs()))\n",
    "\n",
    "error_scores = coeff_differences.groupby('Start Position')['Coefficient Difference'].apply(lambda x:np.std(x.abs()))\n",
    "error_scores[np.isnan(error_scores)] = 0\n",
    "error_scores = error_scores.astype(float)\n",
    "\n",
    "plt.scatter(coeff_differences.groupby('Start Position').mean().index, \n",
    "            all_scores, \n",
    "            s = 500, lw = 10, color='#eb4d4b', alpha = 0.5)\n",
    "\n",
    "plt.errorbar(coeff_differences.groupby('Start Position').mean().index, all_scores, list(error_scores), \n",
    "             lw = 5, linestyle='None', marker='^', color = '#eb4d4b', alpha = 0.8)\n",
    "\n",
    "#plt.xticks(coeff_df.groupby('Sequence Length').mean().index, rotation = 90)\n",
    "plt.xlabel('N-terminus position')\n",
    "plt.ylabel('Mean peptide coefficient')\n",
    "plt.grid()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create plot with std error\n",
    "\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(35, 20)\n",
    "\n",
    "SMALL_SIZE = 60\n",
    "MEDIUM_SIZE = 80\n",
    "BIGGER_SIZE = 90\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    " \n",
    "all_scores = coeff_differences.groupby('End Position')['Coefficient Difference'].apply(lambda x:np.mean(x.abs()))\n",
    "\n",
    "error_scores = coeff_differences.groupby('End Position')['Coefficient Difference'].apply(lambda x:np.std(x.abs()))\n",
    "error_scores[np.isnan(error_scores)] = 0\n",
    "error_scores = error_scores.astype(float)\n",
    "\n",
    "plt.scatter(-1 * coeff_differences.groupby('End Position').mean().index[::-1], \n",
    "            all_scores[::-1], \n",
    "            s = 500, lw = 10, color='#eb4d4b', alpha = 0.5)\n",
    "\n",
    "plt.errorbar(-1 * coeff_differences.groupby('End Position').mean().index[::-1], all_scores[::-1], list(error_scores[::-1]), \n",
    "             lw = 5, linestyle='None', marker='^', color = '#eb4d4b', alpha = 0.8)\n",
    "\n",
    "plt.xlabel('N-terminus position')\n",
    "plt.ylabel('Mean peptide coefficient')\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
